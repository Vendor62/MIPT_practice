{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "\n",
        "# Домашнее задание 2. Поисковая система для документов\n",
        "\n",
        "**Модуль 2. Классический поиск и рекуррентные архитектуры**\n",
        "\n",
        "**ФИО студента:** Поликарпов Дмитрий Александрович\n",
        "\n",
        "**Дата выполнения:** 27.09.2025\n",
        "\n",
        "## Описание задания\n",
        "\n",
        "В этом задании вы разработаете полнофункциональную поисковую систему, включающую:\n",
        "1. **Предобработку корпуса.**\n",
        "2. **BM25.**\n",
        "3. **Векторный поиск** — на основе эмбеддингов.\n",
        "4. **Гибридный поиск** — комбинация BM25 и векторного поиска.\n",
        "5. **Выбор метрики и оценку качества** — для конкретной задачи.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup"
      },
      "source": [
        "## Установка и импорт библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imports"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import math\n",
        "import time\n",
        "import pickle\n",
        "from pathlib import Path\n",
        "from typing import List, Dict, Tuple, Optional, Set\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "# NLP\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pymorphy3\n",
        "\n",
        "# Векторный поиск\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "\n",
        "# BM25\n",
        "from rank_bm25 import BM25Okapi\n",
        "\n",
        "# Создание директорий\n",
        "for dir_name in ['data', 'indices', 'models', 'results', 'tests']:\n",
        "    Path(dir_name).mkdir(exist_ok=True)\n",
        "\n",
        "# Загрузка NLTK ресурсов\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "# Инициализация морфологического анализатора\n",
        "morph = pymorphy3.MorphAnalyzer()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part1"
      },
      "source": [
        "## Часть 1. Подготовка данных\n",
        "\n",
        "1. Загрузите и изучите предложенный датасет.  \n",
        "2. Реализуйте функцию предобработки текста, которая включает:\n",
        "- Лемматизацию с использованием pymorphy3.\n",
        "- Удаление стоп-слов и пунктуации.  \n",
        "3. Обработайте весь корпус документов и сохраните результат для последующих шагов.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "load_data"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating train split: 100%|██████████| 90556/90556 [00:09<00:00, 9797.89 examples/s] \n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Загружаем корпус документов\n",
        "ds = load_dataset(\"MLNavigator/russian-retrieval\")\n",
        "df = pd.DataFrame(ds['train'])\n",
        "questions_df = df[['text','q']]\n",
        "\n",
        "\n",
        "# Уберем дубли, так как датасет имеет соответствие много вопросов -> один документ\n",
        "documents = df['text'].drop_duplicates().to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "preprocessing"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Обработано 0/9076 документов\n",
            "Обработано 1000/9076 документов\n",
            "Обработано 2000/9076 документов\n",
            "Обработано 3000/9076 документов\n",
            "Обработано 4000/9076 документов\n",
            "Обработано 5000/9076 документов\n",
            "Обработано 6000/9076 документов\n",
            "Обработано 7000/9076 документов\n",
            "Обработано 8000/9076 документов\n",
            "Обработано 9000/9076 документов\n",
            "\n",
            "Пример предобработки:\n",
            "Оригинал: В протерозойских отложениях органические остатки встречаются намного чаще, чем в архейских. Они пред...\n",
            "После обработки: протерозойский отложение органический остаток встречаться намного частый архейский представить известковый...\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt_tab', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "\n",
        "russian_stop_words = set(stopwords.words('russian'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "\n",
        "    if not isinstance(text, str):\n",
        "        return []\n",
        "    \n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text, language='russian')\n",
        "    \n",
        "    processed_tokens = []\n",
        "    for token in tokens:\n",
        "\n",
        "        if not token.isalpha():\n",
        "            continue\n",
        "        \n",
        "        parsed = morph.parse(token)[0]\n",
        "        lemma = parsed.normal_form\n",
        "        \n",
        "        if lemma not in russian_stop_words and len(lemma) > 2:\n",
        "            processed_tokens.append(lemma)\n",
        "            \n",
        "    return processed_tokens\n",
        "\n",
        "processed_documents = []\n",
        "for i, doc in enumerate(documents):\n",
        "    if i % 1000 == 0:\n",
        "        print(f\"Обработано {i}/{len(documents)} документов\")\n",
        "    \n",
        "    processed_doc = preprocess_text(doc)\n",
        "    processed_documents.append(processed_doc)\n",
        "\n",
        "print(\"\\nПример предобработки:\")\n",
        "print(\"Оригинал:\", documents[0][:100] + \"...\")\n",
        "print(\"После обработки:\", ' '.join(processed_documents[0][:10]) + \"...\")\n",
        "\n",
        "with open('processed_documents.pkl', 'wb') as f:\n",
        "    pickle.dump(processed_documents, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part2"
      },
      "source": [
        "## Часть 2. Реализация BM25\n",
        "\n",
        "1. Постройте инвертированный индекс для корпуса. Индекс должен содержать частоту термина в документе (TF) и документную частоту (DF).\n",
        "2. Реализуйте функцию поиска BM25 с нуля. Формула для ранжирования:\n",
        "score(D, Q) = Σ IDF(qi) * (f(qi, D) * (k1 + 1)) / (f(qi, D) + k1 * (1 - b + b * |D| / avgdl))\n",
        "3. Проведите оптимизацию гиперпараметра k1, чтобы улучшить качество поиска."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inverted_index"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Документов: 9076, средняя длина: 69.51\n"
          ]
        }
      ],
      "source": [
        "inverted_index = defaultdict(dict)\n",
        "doc_lengths = {}\n",
        "N = len(processed_documents)\n",
        "\n",
        "for doc_id, tokens in enumerate(processed_documents):\n",
        "    term_freqs = Counter(tokens)\n",
        "    doc_lengths[doc_id] = len(tokens)\n",
        "    \n",
        "    for term, freq in term_freqs.items():\n",
        "        inverted_index[term][doc_id] = freq\n",
        "\n",
        "avgdl = sum(doc_lengths.values()) / N\n",
        "print(f\"Документов: {N}, средняя длина: {avgdl:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_idf(term, N=N):\n",
        "    df = len(inverted_index.get(term, {}))\n",
        "    return math.log((N - df + 0.5) / (df + 0.5) + 1)\n",
        "\n",
        "def bm25_score(query_tokens, doc_id, k1=1.5, b=0.75):\n",
        "    score = 0.0\n",
        "    doc_len = doc_lengths[doc_id]\n",
        "    \n",
        "    for term in query_tokens:\n",
        "        if term not in inverted_index:\n",
        "            continue\n",
        "        \n",
        "        idf = compute_idf(term)\n",
        "        f = inverted_index[term].get(doc_id, 0)\n",
        "        if f == 0:\n",
        "            continue\n",
        "        \n",
        "        denom = f + k1 * (1 - b + b * doc_len / avgdl)\n",
        "        score += idf * (f * (k1 + 1)) / denom\n",
        "    return score\n",
        "\n",
        "def bm25_search(query, top_k=5, k1=1.5, b=0.75):\n",
        "    query_tokens = preprocess_text(query)\n",
        "    scores = {}\n",
        "    \n",
        "    for term in query_tokens:\n",
        "        if term not in inverted_index:\n",
        "            continue\n",
        "        for doc_id in inverted_index[term]:\n",
        "            scores.setdefault(doc_id, 0)\n",
        "            scores[doc_id] += bm25_score(query_tokens, doc_id, k1, b)\n",
        "    \n",
        "    ranked_docs = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [(doc_id, score, documents[doc_id][:200]) for doc_id, score in ranked_docs[:top_k]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k1=0.50: accuracy=0.940\n",
            "k1=1.00: accuracy=0.945\n",
            "k1=1.50: accuracy=0.945\n",
            "k1=2.00: accuracy=0.950\n",
            "k1=2.50: accuracy=0.950\n",
            "Лучшее k1: 2.0\n"
          ]
        }
      ],
      "source": [
        "def evaluate_k1(k1_values, sample_size=200, top_k=5):\n",
        "    results = {}\n",
        "    sample = questions_df.sample(sample_size, random_state=42)\n",
        "    \n",
        "    for k1 in k1_values:\n",
        "        hits = 0\n",
        "        for _, row in sample.iterrows():\n",
        "            query = row['q']\n",
        "            doc_text = row['text']\n",
        "            \n",
        "            retrieved = bm25_search(query, top_k=top_k, k1=k1)\n",
        "            if any(doc_text[:100] in r[2] for r in retrieved):\n",
        "                hits += 1\n",
        "        acc = hits / sample_size\n",
        "        results[k1] = acc\n",
        "        print(f\"k1={k1:.2f}: accuracy={acc:.3f}\")\n",
        "    \n",
        "    return results\n",
        "\n",
        "k1_values = [0.5, 1.0, 1.5, 2.0, 2.5]\n",
        "results = evaluate_k1(k1_values)\n",
        "best_k1 = max(results, key=results.get)\n",
        "print(\"Лучшее k1:\", best_k1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Тестирование BM25:\n",
            "\n",
            "Запрос: 'машинное обучение'\n",
            "  [10.670] Особенность программного обеспечения состоит в том, что оно производится в одной форме — в виде исходного текста, а распространяется и используется часто в другой — в виде исполнимых программ, машинны...\n",
            "  [10.344] Промышленный переворот, произошедший с 60-х годов XVIII до первой четверти XIX веко́в в Великобритании, вызвал переход от мануфактуры к крупной машинной индустрии сначала в самой Великобритании, а зат...\n",
            "  [8.975] Цифровые обучающие игры отличаются от традиционных обучающих игр и не основанного на играх электронного обучения тем, что они используют методы мотивации развлекательных игр, чтобы достичь своих образ...\n",
            "\n",
            "Запрос: 'нейронные сети'\n",
            "  [36.560] Области мозга, постоянно используемые, когда человек занят вопросами морали, были исследованы качественными методами мета-анализа изменений мозговой активности и результаты этих исследований отражены ...\n",
            "  [7.731] Двусторонние рынки (двусторонние сети) — сетевые рынки, которые имеют две группы пользователей с возникновением сетевых эффектов между ними. В двусторонней сети присутствует две категории её пользоват...\n",
            "  [7.375] Во множестве сетей пользователи являются гомогенными, то есть они выполняют одинаковые функции. Например, в телефонных сетях один из пользователей посылает, а другой принимает вызов, однако любой из а...\n",
            "\n",
            "Запрос: 'поисковые системы BM25'\n",
            "  [34.086] Для поиска информации с помощью поисковой системы пользователь формулирует поисковый запрос[1]. Работа поисковой системы заключается в том, чтобы по запросу пользователя найти документы, содержащие ли...\n",
            "  [32.238] Полезность поисковой системы зависит от релевантности найденных ею страниц. Хоть миллионы веб-страниц и могут включать некое слово или фразу, но одни из них могут быть более релевантны, популярны или ...\n",
            "  [30.267] Глобальное распространение Интернета и увеличение популярности электронных устройств в арабском и мусульманском мире, в частности, в странах Ближнего Востока и Индийского субконтинента, способствовало...\n",
            "\n",
            "Запрос: 'Python программирование'\n",
            "  [11.534] В теории языков программирования, как подразделе информатики, изучают проектирование, реализацию, анализ и классификацию языков программирования в целом, а также изучают отдельные элементы языков. Эта...\n",
            "  [9.928] Регулирование (системы регулирования) включают в себя контроль (системы контроля). Функции управления делятся на предварительные (прогнозирование, программирование, планирование) и оперативные (исполн...\n",
            "  [9.521] В некоторых университетах информатика преподаётся в качестве теоретического изучения вычислений и автоматического вывода. Такие программы часто включают в себя теорию алгоритмов, анализ алгоритмов, фо...\n"
          ]
        }
      ],
      "source": [
        "test_queries = [\n",
        "    \"машинное обучение\",\n",
        "    \"нейронные сети\",\n",
        "    \"поисковые системы BM25\",\n",
        "    \"Python программирование\"\n",
        "]\n",
        "\n",
        "print(\"Тестирование BM25:\")\n",
        "for query in test_queries:\n",
        "    results = bm25_search(query, top_k=3)\n",
        "    print(f\"\\nЗапрос: '{query}'\")\n",
        "    for doc_id, score, snippet in results:\n",
        "        print(f\"  [{score:.3f}] {snippet}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part3"
      },
      "source": [
        "## Часть 3. Векторный поиск\n",
        "\n",
        "1. Используйте предобученную модель sentence-transformers для получения векторных представлений (эмбеддингов) всех документов.\n",
        "2. Создайте индекс для быстрого поиска ближайших соседей с помощью faiss-cpu.\n",
        "3. Реализуйте функцию векторного поиска, которая по запросу находит top-k наиболее близких документов.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Batches: 100%|██████████| 284/284 [37:03<00:00,  7.83s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Эмбеддинги документов готовы: (9076, 1024)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = SentenceTransformer(\"BAAI/bge-m3\", device=\"cpu\")\n",
        "\n",
        "doc_embeddings = model.encode(documents, convert_to_numpy=True, show_progress_bar=True)\n",
        "\n",
        "print(\"Эмбеддинги документов готовы:\", doc_embeddings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Индекс построен. В нём документов: 9076\n"
          ]
        }
      ],
      "source": [
        "d = doc_embeddings.shape[1]\n",
        "\n",
        "index = faiss.IndexFlatIP(d)  \n",
        "faiss.normalize_L2(doc_embeddings)  \n",
        "index.add(doc_embeddings)\n",
        "\n",
        "print(\"Индекс построен. В нём документов:\", index.ntotal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def vector_search(query, top_k=5):\n",
        "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
        "    faiss.normalize_L2(query_embedding)\n",
        "\n",
        "    D, I = index.search(query_embedding, top_k) \n",
        "    \n",
        "    results = []\n",
        "    for score, doc_id in zip(D[0], I[0]):\n",
        "        results.append((doc_id, float(score), documents[doc_id][:200]))\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Тестирование векторного поиска:\n",
            "\n",
            "Запрос: 'машинное обучение'\n",
            "  [0.484] Моделирование различных процессов, например в гидродинамике, физике, электрике, электронных системах и цепях, а также для моделирования общества и социальных ситуаций (в частности, военных игр), учиты...\n",
            "  [0.483] Принцип Парето лежит в основании идеи компьютерных RISC-процессоров (впрочем, неизвестно, опирались ли авторы идеи на известный им принцип или повторно изобрели его сами). В то время как электронная п...\n",
            "  [0.482] По словам Питера Деннинга, к фундаментальным вопросам информатики относится следующий вопрос: Что может быть эффективно автоматизировано? Изучение теории алгоритмов сфокусировано на поиске ответов на ...\n",
            "\n",
            "Запрос: 'нейронные сети'\n",
            "  [0.524] Области мозга, постоянно используемые, когда человек занят вопросами морали, были исследованы качественными методами мета-анализа изменений мозговой активности и результаты этих исследований отражены ...\n",
            "  [0.503] Нервная ткань млекопитающих, как и у других позвоночных, эктодермального происхождения и состоит из нервных клеток (нейронов) и вспомогательных клеток — нейроглии. Нейроны образуют многочисленные конт...\n",
            "  [0.478] Зеркальные нейроны — это нейроны в головном мозге, которые реагируют на действия, совершаемые другим человеком на глазах у наблюдателя. Они возбуждаются в голове наблюдателя при имитации действий набл...\n",
            "\n",
            "Запрос: 'поисковые системы BM25'\n",
            "  [0.433] Когда пользователь вводит запрос в поисковую систему (обычно при помощи ключевых слов), система проверяет свой индекс и выдаёт список наиболее подходящих веб-страниц (отсортированный по какому-либо кр...\n",
            "  [0.428] Согласно СНиП 2.03.01-84 Бетонные и железобетонные конструкции , класс обозначается латинской буквой B и цифрами, показывающими выдерживаемое давление в мегапаскалях (МПа). Например, обозначение В25 о...\n",
            "  [0.417] Фирма Microsoft впервые запустила поисковую систему Microsoft Network Search (MSN Search) осенью 1998 года, используя результаты поиска от Inktomi. Совсем скоро в начале 1999 года сайт начал отображат...\n",
            "\n",
            "Запрос: 'Python программирование'\n",
            "  [0.551] Особенность программного обеспечения состоит в том, что оно производится в одной форме — в виде исходного текста, а распространяется и используется часто в другой — в виде исполнимых программ, машинны...\n",
            "  [0.522] Первая теория, касающаяся программного обеспечения, была предложена английским математиком Аланом Тьюрингом в 1936 году в эссе On computable numbers with an application to the Entscheidungsproblem ( О...\n",
            "  [0.514] В теории языков программирования, как подразделе информатики, изучают проектирование, реализацию, анализ и классификацию языков программирования в целом, а также изучают отдельные элементы языков. Эта...\n"
          ]
        }
      ],
      "source": [
        "print(\"Тестирование векторного поиска:\")\n",
        "for query in test_queries:\n",
        "    results = vector_search(query, top_k=3)\n",
        "    print(f\"\\nЗапрос: '{query}'\")\n",
        "    for doc_id, score, snippet in results:\n",
        "        print(f\"  [{score:.3f}] {snippet}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part4"
      },
      "source": [
        "## Часть 4. Гибридный поиск\n",
        "\n",
        "1. Разработайте функцию, которая комбинирует результаты ранжирования от BM25 и векторного поиска.\n",
        "2. Реализуйте механизм взвешивания скоров с помощью параметра α:\n",
        "hybrid_score = α * bm25_score + (1 - α) * vector_score\n",
        "3. Проведите автоматическую оптимизацию параметра α на валидационном наборе данных.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def hybrid_search(query, top_k=5, alpha=0.5, k_bm25=10, k_vec=10):\n",
        "    bm25_results = bm25_search(query, top_k=k_bm25)\n",
        "    bm25_scores = {doc_id: score for doc_id, score, _ in bm25_results}\n",
        "    \n",
        "    vec_results = vector_search(query, top_k=k_vec)\n",
        "    vec_scores = {doc_id: score for doc_id, score, _ in vec_results}\n",
        "    \n",
        "    all_doc_ids = set(bm25_scores.keys()) | set(vec_scores.keys())\n",
        "    hybrid_scores = {}\n",
        "    \n",
        "    for doc_id in all_doc_ids:\n",
        "        bm25_score = bm25_scores.get(doc_id, 0.0)\n",
        "        vec_score = vec_scores.get(doc_id, 0.0)\n",
        "        hybrid_scores[doc_id] = alpha * bm25_score + (1 - alpha) * vec_score\n",
        "    \n",
        "    ranked = sorted(hybrid_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "    return [(doc_id, score, documents[doc_id][:200]) for doc_id, score in ranked[:top_k]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "hybrid_search"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Тестирование гибридного поиска:\n",
            "\n",
            "Запрос: 'машинное обучение'\n",
            "  [6.402] Особенность программного обеспечения состоит в том, что оно производится в одной форме — в виде исходного текста, а распространяется и используется часто в другой — в виде исполнимых программ, машинны...\n",
            "  [6.207] Промышленный переворот, произошедший с 60-х годов XVIII до первой четверти XIX веко́в в Великобритании, вызвал переход от мануфактуры к крупной машинной индустрии сначала в самой Великобритании, а зат...\n",
            "  [5.385] Цифровые обучающие игры отличаются от традиционных обучающих игр и не основанного на играх электронного обучения тем, что они используют методы мотивации развлекательных игр, чтобы достичь своих образ...\n",
            "\n",
            "Запрос: 'нейронные сети'\n",
            "  [22.146] Области мозга, постоянно используемые, когда человек занят вопросами морали, были исследованы качественными методами мета-анализа изменений мозговой активности и результаты этих исследований отражены ...\n",
            "  [4.638] Двусторонние рынки (двусторонние сети) — сетевые рынки, которые имеют две группы пользователей с возникновением сетевых эффектов между ними. В двусторонней сети присутствует две категории её пользоват...\n",
            "  [4.425] Во множестве сетей пользователи являются гомогенными, то есть они выполняют одинаковые функции. Например, в телефонных сетях один из пользователей посылает, а другой принимает вызов, однако любой из а...\n",
            "\n",
            "Запрос: 'поисковые системы BM25'\n",
            "  [20.609] Для поиска информации с помощью поисковой системы пользователь формулирует поисковый запрос[1]. Работа поисковой системы заключается в том, чтобы по запросу пользователя найти документы, содержащие ли...\n",
            "  [19.497] Полезность поисковой системы зависит от релевантности найденных ею страниц. Хоть миллионы веб-страниц и могут включать некое слово или фразу, но одни из них могут быть более релевантны, популярны или ...\n",
            "  [18.325] Глобальное распространение Интернета и увеличение популярности электронных устройств в арабском и мусульманском мире, в частности, в странах Ближнего Востока и Индийского субконтинента, способствовало...\n",
            "\n",
            "Запрос: 'Python программирование'\n",
            "  [7.126] В теории языков программирования, как подразделе информатики, изучают проектирование, реализацию, анализ и классификацию языков программирования в целом, а также изучают отдельные элементы языков. Эта...\n",
            "  [5.957] Регулирование (системы регулирования) включают в себя контроль (системы контроля). Функции управления делятся на предварительные (прогнозирование, программирование, планирование) и оперативные (исполн...\n",
            "  [5.713] В некоторых университетах информатика преподаётся в качестве теоретического изучения вычислений и автоматического вывода. Такие программы часто включают в себя теорию алгоритмов, анализ алгоритмов, фо...\n"
          ]
        }
      ],
      "source": [
        "# Тестируем гибридный поиск\n",
        "print(\"Тестирование гибридного поиска:\")\n",
        "for query in test_queries:\n",
        "    results = hybrid_search(query, top_k=3, alpha=0.6)\n",
        "    print(f\"\\nЗапрос: '{query}'\")\n",
        "    for doc_id, score, snippet in results:\n",
        "        print(f\"  [{score:.3f}] {snippet}...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "part6"
      },
      "source": [
        "## Часть 5. Оценка качества\n",
        "\n",
        "1. Выберите и **обоснуйте метрику** для оценки качества вашей поисковой системы (например, MRR, MAP@k или NDCG@k). **Обязательно подумайте о том, какой топ-к нужно выбрать исходя из данных**.\n",
        "2. **Создайте небольшой датасет для оценки**, состоящий из запросов и релевантных им документов.  \n",
        "3. **Сравните качество** всех трех реализованных подходов (BM25, векторный, гибридный) на вашем датасете.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "metrics"
      },
      "outputs": [],
      "source": [
        "eval_sample = questions_df.sample(200, random_state=42).reset_index(drop=True)\n",
        "eval_dataset = list(zip(eval_sample[\"q\"], eval_sample[\"text\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def mrr_at_k(search_fn, eval_dataset, k=5):\n",
        "    reciprocal_ranks = []\n",
        "    \n",
        "    for query, gold_doc in eval_dataset:\n",
        "        results = search_fn(query, top_k=k)\n",
        "        \n",
        "        rank = 0\n",
        "        for i, (doc_id, score, snippet) in enumerate(results, start=1):\n",
        "            if gold_doc[:100] in snippet:\n",
        "                rank = i\n",
        "                break\n",
        "        \n",
        "        if rank > 0:\n",
        "            reciprocal_ranks.append(1.0 / rank)\n",
        "        else:\n",
        "            reciprocal_ranks.append(0.0)\n",
        "    \n",
        "    return sum(reciprocal_ranks) / len(reciprocal_ranks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Оценка качества моделей (MRR@5):\n",
            "BM25: 0.892\n",
            "Vector: 0.828\n",
            "Hybrid: 0.894\n"
          ]
        }
      ],
      "source": [
        "print(\"Оценка качества моделей (MRR@5):\")\n",
        "\n",
        "mrr_bm25 = mrr_at_k(bm25_search, eval_dataset, k=5)\n",
        "print(f\"BM25: {mrr_bm25:.3f}\")\n",
        "\n",
        "mrr_vector = mrr_at_k(vector_search, eval_dataset, k=5)\n",
        "print(f\"Vector: {mrr_vector:.3f}\")\n",
        "\n",
        "mrr_hybrid = mrr_at_k(lambda q, top_k: hybrid_search(q, top_k=top_k, alpha=0.6),\n",
        "                      eval_dataset, k=5)\n",
        "print(f\"Hybrid: {mrr_hybrid:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Выводы:\n",
        "- Для оценки выбрана `MRR@5`, т.к. у нас один релевантный документ на запрос, и важно оценить не только факт нахождения, но и позицию: чем выше документ, тем больше вклад в метрику.\n",
        "- Топ-5 достаточно широк, чтобы система имела шанс поймать релевантный документ, даже если он не на первой позиции.\n",
        "- `BM25` будет сильнее на точных совпадениях (например, технические термины).\n",
        "- `Vector search` лучше на семантических запросах, но требует времени на создание векторной БД.\n",
        "- `Hybrid` почти всегда обгонит обе модели, потому что комбинирует плюсы."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
