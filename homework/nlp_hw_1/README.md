
# ОТЧЕТ ПО ПРОЕКТУ: КЛАССИФИКАЦИЯ ТОНАЛЬНОСТИ ОТЗЫВОВ

## 1. Описание данных

### 1.1. Источник данных
- Датасет: Гео-отзывы (geo-reviews-dataset-2023)
- Размер исходного датасета: 92878 отзывов
- Период: 2023 год
- Язык: Русский

### 1.2. Исходное распределение
- Рейтинги от 1 до 5 звезд
- После фильтрации нейтральных отзывов (рейтинг 3): 92878 отзывов
- Балансировка классов: одинаковое количество позитивных и негативных отзывов

### 1.3. Целевая переменная
- Бинарная классификация: sentiment ∈ [0, 1]
- 0: Негативный (рейтинг 1-2)
- 1: Позитивный (рейтинг 4-5)

## 2. Предобработка текста

### 2.1. Основные этапы обработки
- Приведение к нижнему регистру
- Удаление HTML-тегов и URL-адресов
- Удаление специальных символов и цифр
- Токенизация текста
- Удаление стоп-слов (русский язык)
- Лемматизация с использованием pymorphy3
- Фильтрация по длине слова (min_length=2)

### 2.2. Статистика предобработки
- Средняя длина до обработки: 60.1 слов
- Средняя длина после обработки: 38.4 слов
- Сокращение объема текста: ~30-40%

### 2.3. Визуализация результатов
- Облака слов для позитивных и негативных классов
- Частотный анализ ключевых слов
- Выявление наиболее значимых маркеров тональности

## 3. Методы и модели

### 3.1. TF-IDF + LogisticRegression
- Векторизация: TfidfVectorizer с n-grams (1,3)
- Максимальное количество features: 10,000
- Лучшие параметры: max_features=10000, ngram_range=(1,3)

### 3.2. Word2Vec + LogisticRegression  
- Архитектура: Skip-gram
- Размер вектора: 100
- Размер окна: 10
- Лучшие параметры: vector_size=100, window=10, sg=1

### 3.3. FastText + LogisticRegression
- Архитектура: Skip-gram с subword information
- Размер вектора: 100
- Обработка OOV-слов: включена
- Лучшие параметры: vector_size=100, window=10, sg=1

## 4. Результаты моделей

### 4.1. Сравнительная таблица метрик

| Модель | Accuracy | Precision | Recall | F1-Score | ROC-AUC |
|--------|----------|-----------|--------|----------|---------|
| TF-IDF + LR | 0.9444 | 0.9504 | 0.9377 | 0.9437 | 0.9832 |
| Word2Vec + LR | 0.9414 | 0.9492 | 0.9327 | 0.9393 | 0.9801 |
| FastText + LR | 0.9407 | 0.9487 | 0.9318 | 0.9402 | 0.9800 |

### 4.2. Анализ результатов
- **Лучшая модель**: TF-IDF + LogisticRegression (F1: 0.9437)
- Все модели показали отличное качество (>0.93 F1-Score)
- ROC-AUC > 0.98 у всех моделей - отличная разделяющая способность

### 4.3. Визуализация
- ROC-кривые: все модели близки к идеальной кривой
- Confusion matrices: минимальное количество ошибок
- t-SNE: четкое разделение кластеров по тональности

## 5. Сравнительный анализ

### 5.1. Преимущества TF-IDF
- Высшее качество на чистых текстах
- Быстрое обучение и предсказание
- Простота интерпретации фичей
- Эффективная работа с n-grams

### 5.2. Преимущества эмбеддингов
- Устойчивость к опечаткам (особенно FastText)
- Понимание семантических отношений
- Работа с OOV-словами
- Возможность семантического анализа

### 5.3. Анализ ошибок
- Сложные случаи: нейтральные и ироничные тексты
- Тексты со смешанной тональностью
- Короткие отзывы с недостаточным контекстом

## 6. Ключевые инсайты

### 6.1. Лингвистические паттерны
- **Позитивные маркеры**: отличный, спасибо, хороший, быстро, вежливый
- **Негативные маркеры**: отвратительный, ужасный, испортить, грязный
- Эмоциональные отзывы короче и более интенсивны
- Негативные отзывы часто более развернуты

### 6.2. Семантические отношения
- FastText успешно обрабатывает опечатки и OOV-слова
- Word2Vec выявляет контекстные семантические связи
- Векторная арифметика работает осмысленно

## 7. Рекомендации

### 7.1. Для production системы
- **Основная модель**: TF-IDF + LogisticRegression
- **Fallback модель**: FastText + LogisticRegression
- **Дополнительные фичи**: длина текста, эмоциональные маркеры

### 7.2. Для улучшения качества
- Добавить обработку emoji и смайликов
- Внедрить spell correction для опечаток
- Реализовать ансамблевый подход

