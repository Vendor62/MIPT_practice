{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsVMGiVgSq2"
      },
      "source": [
        "### Классификация FashionMNIST\n",
        "\n",
        "##### Автор: [Радослав Нейчев](https://www.linkedin.com/in/radoslav-neychev/), @neychev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3isBRG6PgSq6"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import torchvision\n",
        "from torchvision.datasets import FashionMNIST\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeA6Q5-CgSq7"
      },
      "source": [
        "### Задача №1:\n",
        "Вернемся к задаче распознавания простых изображений, рассмотренной ранее. Но теперь будем работать с набором данных [FashionMNIST](https://github.com/zalandoresearch/fashion-mnist). В данном задании воспользуемся всем датасетом целиком.\n",
        "\n",
        "__Ваша основная задача: реализовать весь пайплан обучения модели и добиться качества $\\geq 88.5\\%$ на тестовой выборке.__\n",
        "\n",
        "Код для обучения модели в данном задании отсутствует. Присутствует лишь несколько тестов, которые помогут вам отладить свое решение. За примером можно обратиться к ноутбукам с предыдущих занятий."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "nPG1KbQAgl8b"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aYcL28OsgSq8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to .\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:16<00:00, 1.64MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting .\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to .\\FashionMNIST\\raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to .\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 448kB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting .\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to .\\FashionMNIST\\raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to .\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:03<00:00, 1.44MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting .\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to .\\FashionMNIST\\raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to .\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<?, ?B/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting .\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to .\\FashionMNIST\\raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Image label: 3')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJ15JREFUeJzt3Qt4FNX9//HvJuROEi4BkkiAcFduCkVABINQYniqoLQVLy20FiqCFaiX4k9F8BJFqxaL+Pu3lui/CEor4BUL4RJRUEERqQUJBgG5I0lIQi5k5/+cwz9bFoJyxiQn2X2/nmeesJv57sxOhv3smTlzxuM4jiMAANSxkLpeIAAACgEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEE1LFdu3aJx+ORrKws49oHH3xQ1x45cqTG1mfcuHHSrl27Gns94HwRQKhX1Iey+oDduHGj7VXBeZo6dar07t1bmjVrJtHR0XLhhRfqoCwqKrK9aqjnGtleAQAN28cffyyDBg2SX/3qVxIZGSmffvqpPPbYY7Jy5UrJycmRkBC+56J6BBCAH2TdunVnPdehQwe588475aOPPpL+/ftbWS/Uf3w1Qb2nzlE0btxYdu/eLT/5yU/0vy+44AKZO3eu/v3nn38uV155pcTExEjbtm3l5Zdf9qv/9ttv9Ydhjx49dG1cXJxkZGTIZ599dtayvv76a7nmmmv0a7Vs2VIfXnr33Xf1YcE1a9b4zfvhhx/KVVddJfHx8frQ0xVXXCHvv/++q/e4ZcsW/T7bt2+vWxGJiYny61//Wo4ePVrt/Ooc0M9//nP9Xpo3by533HGHlJaWnjXf3//+d+nTp49ERUXpQ2RjxoyRPXv2fO/67N+/X7Zt2yYVFRWu3k/VOaX8/HxX9QgOBBAahMrKSh0aKSkpMnv2bP0BN3nyZH3OSIXAj370I3n88cclNjZWfvnLX0peXp6v9quvvpKlS5fq8Hrqqafkrrvu0qGlAmPfvn2++YqLi3WQqUNHv/vd7+R//ud/5IMPPpB77rnnrPVZtWqVDB48WAoLC2XGjBny6KOP6g9bVa++9ZtasWKFXk91GOvZZ5/VQbFo0SIZMWKEVHfHFBU+KnAyMzP1PHPmzJEJEyb4zfPII4/obdGpUyf9vqdMmSLZ2dl6vb8vGKZPn67P5XzzzTfntf4nT57Uoai257/+9S+577779N/i0ksvNdwSCCrqfkBAfTF//nz1aet8/PHHvufGjh2rn3v00Ud9zx07dsyJiopyPB6Ps2jRIt/z27Zt0/POmDHD91xpaalTWVnpt5y8vDwnIiLCmTVrlu+5P/7xj7p26dKlvudOnDjhdO3aVT+/evVq/ZzX63U6derkpKen639XKSkpcVJTU50f//jH3/ke1bLV66n3enrtmRYuXKjny8nJ8T2n3pd67pprrvGb97bbbtPPf/bZZ/rxrl27nNDQUOeRRx7xm+/zzz93GjVq5Pe82r5t27b1m69qm6t1PR/r16/X81dNXbp08W0v4FxoAaHB+M1vfuP7d5MmTaRLly76UJlqDVRRz6nfqdZElYiICN+JcNWSUoe11KE4Ne8nn3zim2/58uX60J46BFdFHQ4bP36833ps3rxZduzYITfeeKN+LfXNX02qBTV06FB94t3r9Rq9N3WIrIpq2ajXqzp3cvo6Vpk0aZLf49tvv13/fPvtt/XP1157Ta+D2jZV66cmdWhPtYhWr179neujWpaq5XW+3bMvuugi3YpTLc27775b/13oBYfvQycENAgqCFq0aOH3nDr30rp1a31+5sznjx075nusPoj/9Kc/yXPPPacPzakQqqLOn5x+/kedPD/z9Tp27Oj3WIWPMnbs2HOub0FBgTRt2vS83586TzVz5kx92O3QoUNnvdaZVIicTq23Cll1jVHVOqoAOXO+KmFhYVKT1LmoYcOG6X+PHDlSn4dTP1V49urVq0aXhcBBAKFBCA0NNXr+9PMm6vzM/fffr0/qP/TQQ/pkvPqwVudETFsqSlXNE088IRdffHG186gWlgnVUlHnm9T5KfWaql4tR53fOp91PDM0VY167p133ql2G5mun6nrrrtOfvGLX+hAJYBwLgQQAt4//vEPGTJkiLzwwgt+z6sT8QkJCb7HqgfdF198ocPr9A/03Nzcs1obZ37r/yFUa011DlAtoAceeOCsllZ11O9SU1P91lGFTtUhM7WO6n2oeTp37ix1raysTK9Pda03oArngBDwVAvgzJ5kixcvPquHV3p6un7u9ddf9zsf85e//MVvPtWtWX3AP/nkk9We5zh8+LDx+ilnruMzzzxzzpqqLuhVVM85RfUUrGqBqNdVoXbm66rH5+rebdoNW4V4dfP89a9/1T9V70TgXGgBIeCp7tezZs3SXZwvu+wy3QV7wYIF+pqb0/32t7+VP//5z3LDDTfo62qSkpL0fOr8k1LVKlKH79QHrPqw79atm35d1XlBhZc6ua9aRm+88cZ5r5+aX3WNVt3L1Ye5ei3Vlfn0ruRnUr9TnSXUIbr169fr631Up4iqw10qIB9++GHdnVqdFxo1apTuFq3qlixZortsq2ujzkXVvfjii3r+7+qIoK6NUl3Wf/rTn+rzTeXl5fLee+/pThAqfG6++ebz3g4IPgQQAt69996re6ipE+OvvPKKHrfsrbfekj/84Q9nnRdR1/eoHmWq04J6rK6jUaE1evRoXxApaWlp+oNfnVNSoaVaQqqHWb9+/XSQmVLrpparWjaqhTJ8+HB9/iY5Obna+dX7UIfr1Hto1KiRviZKnZM6nfqdOvz29NNP65aQoq6jUq99ek+/H0Jd3KsOby5btky3mtS6q/BT66bOZ4WHh9fIchCYPKovtu2VAOozdShMjYiwd+9e3ToBUDMIIOA0J06cOOuanEsuuUR33f7yyy+trhsQaDgEB5xGnbxv06aN7gqtenCpcyvqZLw6FwSgZhFAwBk94VQHAxU4qtWjrvBX17Jcf/31tlcNCDgcggMAWMF1QAAAKwggAIAV9e4ckBq+Q91TRF00d+b4VgCA+k+d2Tl+/Li+ju27bsle7wJIhY+6WA4A0LCpu++qEesbTACplo9yuYyQRlKzQ8bDPk/vC41rdk403w+aZ/931AIT8YvM72Zar/W5yFXZ15PNjz60esV8m0cu32Rcg/rvpFTIOnnb93le5wGkhhRRQ4McOHBAj0+lBks8n9vzVh12U+HTyEMABRpPqPmHVEi0+X4QGu4ugAJun2vkbjuERJsHUKMw82UF3PbGKf+/b/X3nUaplU4IapyqadOmyYwZM3w3pFLXV5x5oy0AQPCqlQB66qmn9G2M1SjB6kK+559/XqKjo+Vvf/tbbSwOANAA1XgAqeHYN23a5HejLtULQj1WowdXd+OqwsJCvwkAEPhqPICOHDmihzBp1aqV3/PqsTofdKbMzEyJj4/3TfSAA4DgYP1CVHXjKzXoY9Wkuu0BAAJfjfeCS0hI0LcCPnjwoN/z6rG6YdeZIiIi9AQACC413gJSd0Ds06ePZGdn+41uoB4PGDCgphcHAGigauU6INUFe+zYsfqe8OraH3VHSXVLZNUrDgCAWgsgde+Uw4cP6/vCq44H6uZey5cvP6tjAgAgeNW7+wGpbtiqN1yajOQq6Xru0TzzYWs+KOlkXPPJ8TbGNTe3+EDcGBpVaVyTU2q+nD0VzY1rboo9alzzenG0uOFm/ULFa1yz8qj50EzHBx0xrkHdOulUyBpZpjuWxcXF1d9ecACA4EQAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQACAwBkNGw3Lrkfc3afp4xOHjWvez+9gXBMTWm5ck13YTdw4Wvm1cU1a1D7jmgER5oOevl4ca1zz94Pu/rZ94ncb1/zl84HGNZelfmVc89VE8/fUYt56cSUk1LzGa/63DVa0gAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFo2FDKmK9dbaslKhjxjV7TjQ1rnll9WXiRvQw85G3s74xHwV6f2GccU2n5uajj+d+myBuTE7ONq7Z1KaNcc267Z2May6+Ide4pnieuMPI1rWKFhAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWMFgpJAO/zQfgFN5sVN/45pRrbcY17zz6gDjmg5ri8WNjX3aGtfEhZca1+z83Hw5n4n5oKy90r4UN0q9YcY1qTFHjWsOJcca1/Russe45j2JNK5B7aMFBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWMBgp5OuJla7qnuz4jnFN1/DDxjWVN5p/T9o3uom4ManFauOag5WNjWvWXbPPuOb9my82ril4PVncWP+XTsY135bHGNc0Di8zrskrSTCuESlyUYPaRgsIAGAFAQQACIwAevDBB8Xj8fhNXbt2renFAAAauFo5B9StWzdZuXLlfxfSiFNNAAB/tZIMKnASExNr46UBAAGiVs4B7dixQ5KTk6V9+/Zy0003ye7du885b1lZmRQWFvpNAIDAV+MB1K9fP8nKypLly5fLvHnzJC8vTwYNGiTHjx+vdv7MzEyJj4/3TSkpKTW9SgCAYAigjIwM+dnPfiY9e/aU9PR0efvttyU/P19effXVauefPn26FBQU+KY9e/bU9CoBAOqhWu8d0KRJE+ncubPk5uZW+/uIiAg9AQCCS61fB1RUVCQ7d+6UpKSk2l4UACCYA+jOO++UtWvXyq5du+SDDz6Qa6+9VkJDQ+WGG26o6UUBABqwGj8Et3fvXh02R48elRYtWsjll18uGzZs0P8GAKDWAmjRokU1/ZKoZR1bHXFVNyjSvK5/1p3GNZWRxiXyi+FrzYtE5L0THY1rOoQfNK7JiN1iXLPvBfMBViu8oeJGx0jz97Tg7SuMa6aNfF3qwu4rhruqC1n7aY2vC/6LseAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAIDBvSIf6LyXmmKu6fK/XuKb5Vse4Zv+PTxrXvJQ9WNy4pG/1N078Lo+3+dK45jdf3mRcMzZlvXHNzPevETf6XpZnXNPiU/O/7aAbzLd35r4M45pjHV2MaKv2V3dj2uI80QICAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFYyGHWAatb7AuCajqbshf1PDGhvXNNl00LjmeEqScc3n054TN9r/87fGNZtamW/zm1t/aFwzIsZ8hOrMxuXGNcpr+y8xrmn86gbjmm7PRBnX/Ch+l3HN+wM7ihvNX3BVhvNECwgAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArGAw0gBT0s184M7kRsdcLi3MuKIy13xAzYpY8/f086+GihtJ73mMa7pdfcC45pr3bjOueSQ/3LjmraufFjcWFfQ1rtngYn9IfWO8cU1G78+Na7q02y9uOK6qcL5oAQEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQxGGmDyO5kPWPl6QW9Xy9oRtU/qQuO95kNCzmj9pqtlbX6otXHN20XdjWsab4wyrok66jWuybr8MnHj8VabjWvS5WLjmqabzT+Crrpyi3FNfmy0uLFAzPcHnD9aQAAAKwggAEDDCKCcnBy5+uqrJTk5WTwejyxdutTv947jyAMPPCBJSUkSFRUlw4YNkx07dtTkOgMAgjGAiouLpVevXjJ37txqfz979myZM2eOPP/88/Lhhx9KTEyMpKenS2lpaU2sLwAgQBifAczIyNBTdVTr55lnnpH77rtPRo4cqZ976aWXpFWrVrqlNGbMmB++xgCAgFCj54Dy8vLkwIED+rBblfj4eOnXr5+sX7++2pqysjIpLCz0mwAAga9GA0iFj6JaPKdTj6t+d6bMzEwdUlVTSkpKTa4SAKCest4Lbvr06VJQUOCb9uzZY3uVAAANLYASExP1z4MHD/o9rx5X/e5MEREREhcX5zcBAAJfjQZQamqqDprs7Gzfc+qcjuoNN2DAgJpcFAAg2HrBFRUVSW5url/Hg82bN0uzZs2kTZs2MmXKFHn44YelU6dOOpDuv/9+fc3QqFGjanrdAQDBFEAbN26UIUOG+B5PmzZN/xw7dqxkZWXJ3Xffra8VmjBhguTn58vll18uy5cvl8jIyJpdcwBAcAVQWlqavt7nXNToCLNmzdIT6l5omfnAnd9WxLhaVu8m5h1GXhLzXo6ekUeNa7qFmw/2qawqbmxc8/LOvsY1hb3KzZdz5bPGNb/ddpO40fGLS4xrOnc5blzTdLv5dugWfsi4ZkNpW3EjJNp8EFNvSYmrZQUj673gAADBiQACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAgIYxGjbqt5JEj3FNk0buRu/9zbabjWsay1fGNR/3ftW45tEjXcSNsJCTxjUXxBcY15SWhxnXtG1k/rcNC600rtF1X5qPJr4v3bwm+Z0DdfKtudIx33aKpxEfkbWJFhAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWMFIewEmpMK85tFWW1wtq//+zuZFl/ZwsaTNxhU5Rzq6WI7Iz5I2Gdf83w7/NK6Z0/RHxjV/PNrbuObFLgvEjSebDjGuGRb/b+Oa/311kHFN60bmg562Cz8ibniaxpsXFRa6WlYwogUEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYwGGmAafVRmXFN2tZRrpYV91CMcc2By8xryhzzEVZ/3XqduPFxUXvjmv9zMta4ZkjsF8Y1OUVdjWsqHHHlsthc45prYkqMa/7X4zGu6fyvCcY10XGl4kbbgr2u6nB+aAEBAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUMRhpgGq3a5KJG6kz5tB7GNRVOpXFNXllLcWNnUYJxzdBk84FFB0cal8gt/xhiXDM/PM18QSLySMYrxjUl3nLjGsfrNa7p/Cvzfdwt8z0PJmgBAQCsIIAAAA0jgHJycuTqq6+W5ORk8Xg8snTpUr/fjxs3Tj9/+nTVVVfV5DoDAIIxgIqLi6VXr14yd+7cc86jAmf//v2+aeHChT90PQEAwd4JISMjQ0/fJSIiQhITE3/IegEAAlytnANas2aNtGzZUrp06SITJ06Uo0ePnnPesrIyKSws9JsAAIGvxgNIHX576aWXJDs7Wx5//HFZu3atbjFVVlbfoTEzM1Pi4+N9U0pKSk2vEgAgGK4DGjNmjO/fPXr0kJ49e0qHDh10q2jo0KFnzT99+nSZNm2a77FqARFCABD4ar0bdvv27SUhIUFyc3PPeb4oLi7ObwIABL5aD6C9e/fqc0BJSUm1vSgAQCAfgisqKvJrzeTl5cnmzZulWbNmepo5c6aMHj1a94LbuXOn3H333dKxY0dJT0+v6XUHAARTAG3cuFGGDPnvmFRV52/Gjh0r8+bNky1btsiLL74o+fn5+mLV4cOHy0MPPaQPtQEA4DqA0tLSxHGcc/7+3XffNX1J2ObxuKv7jv3gXDq0OGJcc9/By41r3lneV9xI/Yf5ZQCfvNjOuOaL0grjGm9SqXHNJe32iBuF3ijjmryT5kN3ll/Y2rgm9OAh45qQSBejv6ptXmq+zXH+GAsOAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAgXFLbjTAka1djGrt1sTWq41rjp5sbFzTe/QucePJbj82X1a0+bLKnVDjGm+p+X/XDo3NRx9XSrzhxjUL8y81rjnY13yU6uQ1xiXiLTcffRy1jxYQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFjBYKSoU/mVMcY1Xhffk3JLW4kb83ouMK6J9Jw0rklpZD445q39zUfh/Kasibjhdcy3+bDYfxvXLOjcX+qEt7JulgMjtIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoGIw00HhffKRx3AzWGxJgPLPpJUVvjmsPljY1r3l9/kbiRmnHYuCYl7KhxTYvQY8Y1l0TtMq65IqZU3NhSlmJcEx1SZlzT6Fg9/wjyeMxrHKc21iQg0QICAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACvq+UiAMOUJMR880fG6W1bhiO7GNZMT/mhcM3TN74xrog67+271ZWmicc0FYeYDi5Y65n+nruHmy3ny0BBx40RluHHNxZFfG9fEXWg+kCsCBy0gAIAVBBAAoP4HUGZmpvTt21diY2OlZcuWMmrUKNm+fbvfPKWlpTJp0iRp3ry5NG7cWEaPHi0HDx6s6fUGAARTAK1du1aHy4YNG2TFihVSUVEhw4cPl+LiYt88U6dOlTfeeEMWL16s59+3b59cd911tbHuAIBg6YSwfPlyv8dZWVm6JbRp0yYZPHiwFBQUyAsvvCAvv/yyXHnllXqe+fPny4UXXqhDq3///jW79gCA4DwHpAJHadasmf6pgki1ioYNG+abp2vXrtKmTRtZv359ta9RVlYmhYWFfhMAIPC5DiCv1ytTpkyRgQMHSvfup7rjHjhwQMLDw6VJkyZ+87Zq1Ur/7lznleLj431TSor5vegBAEEUQOpc0NatW2XRokU/aAWmT5+uW1JV0549e37Q6wEAAvhC1MmTJ8ubb74pOTk50rp1a9/ziYmJUl5eLvn5+X6tINULTv2uOhEREXoCAAQXoxaQ4zg6fJYsWSKrVq2S1NRUv9/36dNHwsLCJDs72/ec6qa9e/duGTBgQM2tNQAguFpA6rCb6uG2bNkyfS1Q1Xkdde4mKipK/7zllltk2rRpumNCXFyc3H777Tp86AEHAHAdQPPmzdM/09LS/J5XXa3HjRun//30009LSEiIvgBV9XBLT0+X5557zmQxAIAg0Mj0ENz3iYyMlLlz5+oJga04KdS4ptQx7/fyaP8lxjXDrtwrbnxWHmdcU+qEGde88O1A45q3F1xmXDPipg/EjaktVktduKbNVuOaD8R8oFTUT4wFBwCwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAgIZzR1RAKexYaVxT4pjvcmEe8+XEh0SKGx8WdzSuaRtxxLhmRouPjGuyj5nf1HHtk+7uw/Xw7E3GNbtPnjCu6R5lPmr5B9Je6ozHxXd0x3x/DVa0gAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgYjDTBOZR0OhBh30rgkVBzjmmJvuHFNkbdM3IgOdVdnvJwQ8/d087R3jGtWHr5Q3Hi1qKVxzZr8rsY1HaMPGdeEXtTZuKbyiy/FDU+Ix7jG8bpaVFCiBQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVjAYaaBxzAf7dCs58ZhxTWxIhXHNo1syjGtiLl4mbhwqjzOuuSjiG6kLfaO+Mq4ZkfpvV8taUnixcc2g+O3GNSXeCOOaY72aGdfEfWFcgjpACwgAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArGAwUriWGFNoXHPUxeCTw9tvM67JiD4ibvxhyU3GNW907m5c83m/l41rwjyVxjV/+HqUuDE0wXybXxy517imSchJ45rnE0Ya15gPMYu6QAsIAGAFAQQAqP8BlJmZKX379pXY2Fhp2bKljBo1SrZv978HSFpamng8Hr/p1ltvren1BgAEUwCtXbtWJk2aJBs2bJAVK1ZIRUWFDB8+XIqLi/3mGz9+vOzfv983zZ49u6bXGwAQTJ0Qli9f7vc4KytLt4Q2bdokgwcP9j0fHR0tiYmJNbeWAICA84POARUUFOifzZr53yJ3wYIFkpCQIN27d5fp06dLSUnJOV+jrKxMCgsL/SYAQOBz3Q3b6/XKlClTZODAgTpoqtx4443Stm1bSU5Oli1btsg999yjzxO99tpr5zyvNHPmTLerAQAItgBS54K2bt0q69at83t+woQJvn/36NFDkpKSZOjQobJz507p0KHDWa+jWkjTpk3zPVYtoJSUFLerBQAI5ACaPHmyvPnmm5KTkyOtW7f+znn79eunf+bm5lYbQBEREXoCAAQXowByHEduv/12WbJkiaxZs0ZSU1O/t2bz5s36p2oJAQDgKoDUYbeXX35Zli1bpq8FOnDggH4+Pj5eoqKi9GE29fsRI0ZI8+bN9TmgqVOn6h5yPXv2NFkUACDAGQXQvHnzfBebnm7+/Pkybtw4CQ8Pl5UrV8ozzzyjrw1S53JGjx4t9913X82uNQAg+A7BfRcVOOpiVQAAvg+jYcO1jIStxjUxHvPRjx9KzDGuiQ6JEjc69N1tXNMtfr/UhV7h5jVTWq9wtazBkW6qzIv+U37uawTPpSTpu78Io+FgMFIAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsILBSOHa3DnXGtc81s58ORHHPMY1oaXiSnm8ec32donGNW+9depOwSbKUsqNayIbm9coIZ/EGteUpJgPNNu5yz7jmrZvn5C64pw0f084f7SAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFfVuLDjHcfTPk1IhcuqfqKcqy80HXPO6GKOtssx8LDgpMy/Ry3Kxft4T5gurLPW6WI75uG6VIe7GgnPKwoxrvCfMx007WWy+7bwnzf9IIU6FcQ3c05/fp32en4vH+b456tjevXslJSXF9moAAH6gPXv2SOvWrRtOAHm9Xtm3b5/ExsaKx+P/zbewsFCHk3pTcXFxEqzYDqewHU5hO5zCdqg/20HFyvHjxyU5OVlCQkIaziE4tbLflZiK2qjBvINVYTucwnY4he1wCtuhfmyH+Pjvv7cJnRAAAFYQQAAAKxpUAEVERMiMGTP0z2DGdjiF7XAK2+EUtkPD2w71rhMCACA4NKgWEAAgcBBAAAArCCAAgBUEEADACgIIAGBFgwmguXPnSrt27SQyMlL69esnH330ke1VqnMPPvigHp7o9Klr164S6HJycuTqq6/Ww3qo97x06VK/36uOnA888IAkJSVJVFSUDBs2THbs2CHBth3GjRt31v5x1VVXSSDJzMyUvn376qG6WrZsKaNGjZLt27f7zVNaWiqTJk2S5s2bS+PGjWX06NFy8OBBCbbtkJaWdtb+cOutt0p90iAC6JVXXpFp06bpvu2ffPKJ9OrVS9LT0+XQoUMSbLp16yb79+/3TevWrZNAV1xcrP/m6ktIdWbPni1z5syR559/Xj788EOJiYnR+4f6IAqm7aCowDl9/1i4cKEEkrVr1+pw2bBhg6xYsUIqKipk+PDhettUmTp1qrzxxhuyePFiPb8aW/K6666TYNsOyvjx4/32B/V/pV5xGoBLL73UmTRpku9xZWWlk5yc7GRmZjrBZMaMGU6vXr2cYKZ22SVLlvgee71eJzEx0XniiSd8z+Xn5zsRERHOwoULnWDZDsrYsWOdkSNHOsHk0KFDelusXbvW97cPCwtzFi9e7JvnP//5j55n/fr1TrBsB+WKK65w7rjjDqc+q/ctoPLyctm0aZM+rHL6gKXq8fr16yXYqENL6hBM+/bt5aabbpLdu3dLMMvLy5MDBw747R9qEER1mDYY9481a9boQzJdunSRiRMnytGjRyWQFRQU6J/NmjXTP9VnhWoNnL4/qMPUbdq0Cej9oeCM7VBlwYIFkpCQIN27d5fp06dLSUmJ1Cf1bjTsMx05ckQqKyulVatWfs+rx9u2bZNgoj5Us7Ky9IeLak7PnDlTBg0aJFu3btXHgoORCh+luv2j6nfBQh1+U4eaUlNTZefOnXLvvfdKRkaG/uANDQ2VQKNu3TJlyhQZOHCg/oBV1N88PDxcmjRpEjT7g7ea7aDceOON0rZtW/2FdcuWLXLPPffo80Svvfaa1Bf1PoDwX+rDpErPnj11IKkd7NVXX5VbbrnF6rrBvjFjxvj+3aNHD72PdOjQQbeKhg4dKoFGnQNRX76C4Tyom+0wYcIEv/1BddJR+4H6cqL2i/qg3h+CU81H9e3tzF4s6nFiYqIEM/Utr3PnzpKbmyvBqmofYP84mzpMq/7/BOL+MXnyZHnzzTdl9erVfvcPU39zddg+Pz8/KPaHyefYDtVRX1iV+rQ/1PsAUs3pPn36SHZ2tl+TUz0eMGCABLOioiL9bUZ9swlW6nCT+mA5ff9Qd4RUveGCff9Qt7dX54ACaf9Q/S/Uh+6SJUtk1apV+u9/OvVZERYW5rc/qMNO6lxpIO0Pzvdsh+ps3rxZ/6xX+4PTACxatEj3asrKynK++OILZ8KECU6TJk2cAwcOOMHk97//vbNmzRonLy/Pef/9951hw4Y5CQkJugdMIDt+/Ljz6aef6kntsk899ZT+99dff61//9hjj+n9YdmyZc6WLVt0T7DU1FTnxIkTTrBsB/W7O++8U/f0UvvHypUrnd69ezudOnVySktLnUAxceJEJz4+Xv8/2L9/v28qKSnxzXPrrbc6bdq0cVatWuVs3LjRGTBggJ4CycTv2Q65ubnOrFmz9PtX+4P6v9G+fXtn8ODBTn3SIAJIefbZZ/VOFR4errtlb9iwwQk2119/vZOUlKS3wQUXXKAfqx0t0K1evVp/4J45qW7HVV2x77//fqdVq1b6i8rQoUOd7du3O8G0HdQHz/Dhw50WLVrobsht27Z1xo8fH3Bf0qp7/2qaP3++bx71xeO2225zmjZt6kRHRzvXXnut/nAOpu2we/duHTbNmjXT/yc6duzo3HXXXU5BQYFTn3A/IACAFfX+HBAAIDARQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIDY8P8AN8YLrwAE3UoAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "\n",
        "train_fmnist_data = FashionMNIST(\n",
        "    \".\", train=True, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "test_fmnist_data = FashionMNIST(\n",
        "    \".\", train=False, transform=torchvision.transforms.ToTensor(), download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_data_loader = torch.utils.data.DataLoader(\n",
        "    train_fmnist_data, batch_size=32, shuffle=True, num_workers=2\n",
        ")\n",
        "\n",
        "test_data_loader = torch.utils.data.DataLoader(\n",
        "    test_fmnist_data, batch_size=32, shuffle=False, num_workers=2\n",
        ")\n",
        "\n",
        "random_batch = next(iter(train_data_loader))\n",
        "_image, _label = random_batch[0][0], random_batch[1][0]\n",
        "plt.figure()\n",
        "plt.imshow(_image.reshape(28, 28))\n",
        "plt.title(f\"Image label: {_label}\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6jWRv1rgSq8"
      },
      "source": [
        "Постройте модель ниже. Пожалуйста, не стройте переусложненную сеть, не стоит делать ее глубже четырех слоев (можно и меньше). Ваша основная задача – обучить модель и получить качество на отложенной (тестовой выборке) не менее 88.5% accuracy.\n",
        "\n",
        "__Внимание, ваша модель должна быть представлена именно переменной `model`. На вход ей должен приходить тензор размерностью (1, 28, 28).__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BcyEFX-RgSq8"
      },
      "outputs": [],
      "source": [
        "# Creating model instance\n",
        "model = None\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # (1,28,28) -> (32,28,28)\n",
        "        self.pool = nn.MaxPool2d(2, 2)                           # (32,28,28) -> (32,14,14)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1) # (64,14,14)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))  # -> (32,28,28)\n",
        "        x = self.pool(x)           # -> (32,14,14)\n",
        "        x = F.relu(self.conv2(x))  # -> (64,14,14)\n",
        "        x = self.pool(x)           # -> (64,7,7)\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAoLV4dkoy5M"
      },
      "source": [
        "Не забудьте перенести модель на выбранный `device`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Xas9SIXDoxvZ"
      },
      "outputs": [],
      "source": [
        "model = CNNModel().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pLRWysggSq9"
      },
      "source": [
        "Локальные тесты для проверки вашей модели доступны ниже:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_qMQzo1ggSq9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Everything seems fine!\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert model is not None, \"Please, use `model` variable to store your model\"\n",
        "\n",
        "try:\n",
        "    x = random_batch[0].to(device)\n",
        "    y = random_batch[1].to(device)\n",
        "\n",
        "    # compute outputs given inputs, both are variables\n",
        "    y_predicted = model(x)\n",
        "except Exception as e:\n",
        "    print(\"Something is wrong with the model\")\n",
        "    raise e\n",
        "\n",
        "\n",
        "assert y_predicted.shape[-1] == 10, \"Model should predict 10 logits/probas\"\n",
        "\n",
        "print(\"Everything seems fine!\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suRmIPwIgSq9"
      },
      "source": [
        "Настройте параметры модели на обучающей выборке. Также рекомендуем поработать с `learning rate`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YJnU14bdnZa_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Test Accuracy = 88.66%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2: Test Accuracy = 90.18%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                               \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3: Test Accuracy = 90.90%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4: Test Accuracy = 91.78%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5: Test Accuracy = 91.59%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6: Test Accuracy = 90.94%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7: Test Accuracy = 92.24%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8: Test Accuracy = 91.85%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9: Test Accuracy = 91.63%\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                  \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10: Test Accuracy = 92.02%\n",
            "\n",
            "Final Test Accuracy: 92.02%\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from tqdm import tqdm\n",
        "\n",
        "learning_rate = 0.001\n",
        "epochs = 10\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in dataloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    return correct / total\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    loop = tqdm(train_data_loader, desc=f\"Epoch [{epoch+1}/{epochs}]\", leave=False)\n",
        "\n",
        "    for images, labels in loop:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    acc = evaluate(model, test_data_loader)\n",
        "    print(f\"Epoch {epoch+1}: Test Accuracy = {acc * 100:.2f}%\")\n",
        "\n",
        "final_acc = evaluate(model, test_data_loader)\n",
        "print(f\"\\nFinal Test Accuracy: {final_acc * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zce7gt1gSq-"
      },
      "source": [
        "Также, напоминаем, что в любой момент можно обратиться к замечательной [документации](https://pytorch.org/docs/stable/index.html) и [обучающим примерам](https://pytorch.org/tutorials/).  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usswrWYOgSq-"
      },
      "source": [
        "Оценим качество классификации:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Xua3TVZHgSq-"
      },
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "real_labels = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in train_data_loader:\n",
        "        y_predicted = model(batch[0].to(device))\n",
        "        predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "        real_labels.append(batch[1])\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels)\n",
        "real_labels = torch.cat(real_labels)\n",
        "train_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "acH7vb5IgSq-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neural network accuracy on train set: 0.9823\n"
          ]
        }
      ],
      "source": [
        "print(f\"Neural network accuracy on train set: {train_acc:3.5}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "l9KEKXBxgSq-"
      },
      "outputs": [],
      "source": [
        "predicted_labels = []\n",
        "real_labels = []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for batch in test_data_loader:\n",
        "        y_predicted = model(batch[0].to(device))\n",
        "        predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "        real_labels.append(batch[1])\n",
        "\n",
        "predicted_labels = torch.cat(predicted_labels)\n",
        "real_labels = torch.cat(real_labels)\n",
        "test_acc = (predicted_labels == real_labels).type(torch.FloatTensor).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dhpenaYKgSq_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Neural network accuracy on test set: 0.9202\n"
          ]
        }
      ],
      "source": [
        "print(f\"Neural network accuracy on test set: {test_acc:3.5}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oyhmMobgSq_"
      },
      "source": [
        "Проверка, что необходимые пороги пройдены:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "OAIrURCEgSq_"
      },
      "outputs": [],
      "source": [
        "assert test_acc >= 0.885, \"Train accuracy is below 0.885 threshold\"\n",
        "assert (\n",
        "    train_acc >= 0.905\n",
        "), \"Test accuracy is below 0.905 while test accuracy is fine. We recommend to check your model and data flow\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xai8JL3tgSq_"
      },
      "source": [
        "### Сдача задания\n",
        "Загрузите файл `hw10_data_dict.npy` (ссылка есть на странице с заданием) и запустите код ниже для генерации посылки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SZ2z-07TgSrA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File saved to `submission_dict_hw10.json` and `submission_dict_hw10.npy`\n"
          ]
        }
      ],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "import os\n",
        "import json\n",
        "\n",
        "\n",
        "assert os.path.exists(\n",
        "    \"hw10_data_dict.npy\"\n",
        "), \"Please, download `hw10_data_dict.npy` and place it in the working directory\"\n",
        "\n",
        "\n",
        "def get_predictions(model, eval_data, step=10):\n",
        "\n",
        "    predicted_labels = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for idx in range(0, len(eval_data), step):\n",
        "            y_predicted = model(eval_data[idx : idx + step].to(device))\n",
        "            predicted_labels.append(y_predicted.argmax(dim=1).cpu())\n",
        "\n",
        "    predicted_labels_np = torch.cat(predicted_labels).numpy()\n",
        "    predicted_labels_str = \",\".join([str(x) for x in list(predicted_labels)])\n",
        "    return predicted_labels_np, predicted_labels_str\n",
        "\n",
        "\n",
        "loaded_data_dict = np.load(\"hw10_data_dict.npy\", allow_pickle=True)\n",
        "\n",
        "train_labels_np, train_labels_str = get_predictions(\n",
        "    model, torch.FloatTensor(loaded_data_dict.item()[\"train\"])\n",
        ")\n",
        "test_labels_np, test_labels_str = get_predictions(\n",
        "    model, torch.FloatTensor(loaded_data_dict.item()[\"test\"])\n",
        ")\n",
        "\n",
        "submission_dict_str = {\n",
        "    \"train\": train_labels_str,\n",
        "    \"test\": test_labels_str,\n",
        "}\n",
        "\n",
        "submission_dict_np = {\n",
        "    \"train\": train_labels_np,\n",
        "    \"test\": test_labels_np,\n",
        "}\n",
        "\n",
        "np.save(\"submission_dict_hw10.npy\", submission_dict_np, allow_pickle=True)\n",
        "with open(\"submission_dict_hw10.json\", \"w\") as iofile:\n",
        "    json.dump(submission_dict_str, iofile)\n",
        "print(\"File saved to `submission_dict_hw10.json` and `submission_dict_hw10.npy`\")\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtWnYAN_gSrA"
      },
      "source": [
        "На этом задание завершено. Поздравляем!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
